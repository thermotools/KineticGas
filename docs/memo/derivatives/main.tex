\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{parskip}
\usepackage{amsmath}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{appendix}

\numberwithin{figure}{section}
\numberwithin{table}{section}

\title{Derivatives of ab initio potentials}
\author{Vegard G. Jervell}
\date{January 2025}

\begin{document}

\maketitle

\section*{Introduction}

When working with Feynman-Hibbs (FH) corrected potentials, we need the derivatives of our potential. The required order of derivatives increases rapidly with the FH-correction order, such that the use of automatic differentiation quickly becomes unfeasible.

Therefore, we wish to express the analytical derivatives of our potentials in a form that allows the $n$'th derivative to be evaluated, without needing to carry out a bunch of differentiation each time we want to increase the FH-correction order.

For some potentials this is straight forward, however popular ab inito potentials commonly use more complex functional forms that make the exercise of deriving explicit expressions for arbitrary derivatives slightly more of a hassle.

This memo intends to give some expressions that are useful when expressing the derivatives of ab initio potentials.

\tableofcontents

\section{Utility functions}

Ab inito potentials typically consist of several terms of the form
\begin{equation}
    t(r) = f(r) \exp(g(r)) \equiv f(r) E(r),
\end{equation}
where $f$ and $g$ are polynomials in positive and/or negative powers of $r$, and the second equality defines $E$. In the simplest case, $g$ is a linear function of $r$, such that $g'(r) = g_1$, and we can express the $n$'th derivative of $t$ as 
\begin{equation}
    t^{(n)}(r) = E(r) \sum_{k = 0}^{n} \binom{n}{k}g_1^{n - k} f^{(k)}(r).
    \label{eq:simple_deriv}
\end{equation}
This result is obtained by differentiating $t$ a couple of times, collecting terms of equal differentiation order of $f$, and recognising the pattern.

If $g$ is anything more complex than a linear function of $r$, we can carry out the same exercise, and find that
\begin{equation}
    t^{(n)}(r) = E(r) \sum_{k = 0}^n \binom{n}{k}G_{n - k}(r) f^{(k)}(r),
\end{equation}
where $G_k(r)$ are functions generated by the recursion
\begin{equation}
    \begin{split}
        G_{k + 1} &= g'(r) G_k + G_{k}', \quad G_0 = 1.
    \end{split}
    \label{eq:gn_recurse}
\end{equation}

Writing out the first few values of $G_k$, using $g_n \equiv g^{(n)}$ for notational convenience gives us
\begin{equation}
    \begin{split}
        G_1 &= g_1 \\
        G_2 &= g_1^2 + g_2 \\
        G_3 &= g_1^3 + 3 g_1 g_2 + g_3 \\
        G_4 &= g_1^4 + 6 g_1^2 g_2 + 3 g_2^2 + 4 g_1 g_3 + g_4,
    \end{split}
\end{equation}
and after some head-scratching we can conclude that $G_n$ may be expressed on closed form as
\begin{equation}
    G_k = \sum_{p \vdash k} Z_p \prod_{l \in p} g_l,
\end{equation}
where the sum over $p \vdash k$ indicates that we are summing over all integer partitions of $k$, $Z_p$ is the multiplicity of the partition $p$, and the product is over the elements of a given partition. For example, $n = 4$ has the unique partitions
\begin{itemize}
    \item (4)
    \item (3, 1)
    \item (2, 2)
    \item (2, 1, 1)
    \item (1, 1, 1, 1)
\end{itemize}
where each partition corresponds to one of the terms in $G_4$.

\begin{figure}[tbh]
    \centering
    \includegraphics[width=0.7\linewidth]{partitions.pdf}
    \caption{An algorithm for determining the unique partitions of an integer $N$}
    \label{fig:partitions_flowchart}
\end{figure}

\subsection{Integer partitions}

The task of expressing the $n$'th derivative of our composite function $f(r) \exp(g(r))$, given that the $n$'th derivatives of $f$ and $g$ are known, has now been reduced to the problem of determining all integer partitions of $n$, and their multiplicity. An illustration of a recursive algorithm for finding the unique partitions of an integer $N$ is shown in Fig. \ref{fig:partitions_flowchart}. 

The basic idea of the algorithm illustrated in Fig. \ref{fig:partitions_flowchart} is as follows: The number $N$ can be partitioned into a part $n = N - k$, which can be combined with any of the partitions of $k$ with largest element $\max\{p_k\} \leq n$ to generate a unique partition of $N$. We iterate over all possible values of $k$ $\in$ $[0, N)$, and for each value, generate the partitions $(n, p_1^{(k, n)})$, $(n, p_2^{(k, n)})$, ..., where $p_i^{(k, n)}$ indicate the partitions of $k$ with $\max\{p_i^{(k, n)}\} \leq n$. Note that we need to exclude partitions of $k$ with elements larger than $n$ to avoid generating several permutations of the same partition. The partitions of $k$ can be found recursively, since $k < N$ and the partition of $0$ is the empty set.

The multiplicity of a partition of $n$ is equal to the number of ways a set of $n$ elements can be subdivided into sets of the sizes given by the partition.\footnote{This can be recognised by writing the expressions for $G_k$ as a graph, with each term being a node linked to the nodes that contribute to it. The multiplicity essentially tells us how many different ways we can get to a certain combination of derivatives using the recursion of Eq.~\eqref{eq:gn_recurse}.} 

In order to find the multiplicity of a partition $p$ of $n$, we start from a set of $n$ elements, that must be subdivided into $m$ subsets each containing $p = (k_1, k_2, ... k_m)$ elements, there are exactly $\binom{n}{k_1}$ ways to assemble the first subset. This leaves $n - k_1$ elements, such that there are $\binom{n - k_1}{k_2}$ ways of assembling the second subset, and $\binom{n - k_1 - k_2 - ... - k_m}{k_m}$ ways of assembling the $m$'th subset. The total number of possible arrangements is then $\binom{n}{k_1}\binom{n - k_1}{k_2}\binom{n - k_1 - k_2}{k_3} \hdots \binom{n - k_1 - k_2 - ... - k_m}{k_m}$. 

If the number of subsets with $l$ elements is $N_l$, there will be $N_l!$ equivalent arrangements that arise from swapping two subsets with $l$ elements. This yields a total of $N_1! N_2! \hdots N_l!$ equivalent arrangements. Thus, the number of distinct partitions of $n$ elements into $m$ subsets each containing $p = (k_1, k_2, ..., k_m)$ elements is
\begin{equation}
    Z_p = \frac{\binom{n}{k_1}\binom{n - k_1}{k_2}\binom{n - k_1 - k_2}{k_3} \hdots \binom{n - k_1 - k_2 - ... - k_m}{k_m}}{N_1! N_2! ... N_l!},
    \label{eq:multiplicity}
\end{equation}

After expanding the binomial coefficients, we can rewrite Eq. \eqref{eq:multiplicity} as
\begin{equation}
    Z_p = \frac{n!}{(k_1! k_2! \hdots k_m!)(N_1! N_2! \hdots N_l!)}.
\end{equation}
and for clarity write out the $n = 4$ case as
\begin{itemize}
    \item $Z_{(4)} = \frac{4!}{(4!)(1!)} = 1$ 
    \item $Z_{(3, 1)} = \frac{4!}{(3! 1!)(1! 1!)} = 4$
    \item $Z_{(2, 2)} = \frac{4!}{(2! 2!)(2!)} = 3$
    \item $Z_{(2, 1, 1)} = \frac{4!}{(2! 1! 1!)(1! 2!)} = 6$
    \item $Z_{(1, 1, 1, 1)} = \frac{4!}{(1! 1! 1! 1!)(4!)} = 1$
\end{itemize}

Note that the size of these factorials grows rapidly with required derivative order,\footnote{For $t^{(n)}(r)$ we need $G_{n}$, which requires us to evaluate $n!$, meaning that we run out of 64-bit integer space at $n \approx 20$. The $n$'th Feynman-Hibbs correction requires the $2n$'th derivative, so this starts becoming an issue already at FH10.} even though the fractions in the multiplicities mean that the factorials will largely cancel out. Luckily we already have an implementation that can handle evaluation of arbitrarily large factorial fractions, as long as the result is not too large or too small. These calculations should probably be implemented using those data structures to avoid overflow issues.

\subsection{Polynomials}

In our use-case, the functions $f$ and $g$ of the previous section are typically polynomials including both positive and negative powers of $r$. It may therefore be useful to note that a polynomial of non-negative powers of $r$,
\begin{equation}
    P_{\ell +} = \sum_{k = 0}^{\ell} C_k r^k,
\end{equation}
in general has the $n$'th derivative
\begin{equation}
    P_{\ell+}^{(n)} = \sum_{k = n}^{\ell} \frac{k! C_k}{(k - n)!} r^{k - n}.
    \label{eq:pos_poly_deriv}
\end{equation}
Likewise, a polynomial in negative powers of $r$,
\begin{equation}
    P_{\ell -} = \sum_{k = 1}^{\ell} C_k r^{-k} = \sum_{k = - \ell}^{-1} C_{-k} r^k
\end{equation}
has $n$'th derivative
\begin{equation}
    \begin{split}
        P_{\ell -}^{(n)} &= (-1)^n \sum_{k = 1}^{\ell} \frac{(k + n - 1)! C_k}{(k - 1)!} r^{-k -n} \\
        &= (-1)^n \sum_{k = - \ell}^{-1} \frac{(n - k - 1)! C_{-k}}{(-k - 1)!} r^{k - n}
    \end{split}
\end{equation}
A polynomial containing both positive and negative powers of $r$, 
\begin{equation}
    P_{\ell_-, \ell_+} = \sum_{k = - \ell_-}^{\ell_+} C_k r^k = \sum_{k = 1}^{\ell_-} C_{-k} r^{-k} + \sum_{k = 0}^{\ell_+} C_k r^k
\end{equation}
thus has $n$'th derivative
\begin{equation}
    \begin{split}
        P_{\ell_-, \ell_+}^{(n)} &= (-1)^n \sum_{k = 1}^{\ell_-} \frac{(k + n - 1)! C_{-k}}{(k - 1)!} r^{-k -n} + \sum_{k = n}^{\ell_+} \frac{k! C_k}{(k - n)!} r^{k - n} \\
        &= \sum_{k = - \ell_-}^{\ell_+} 
        \begin{cases}
            (-1)^n \frac{(n - k - 1)! C_{-k}}{(-k - 1)!} r^{k - n}, & k < 0 \\
            0, & 0 < k < n \\ 
            \frac{k! C_k}{(k - n)!} r^{k - n}, & n \leq k
        \end{cases}
    \end{split}
\end{equation}

For notational convenience we will use $E_{\ell} \equiv \exp(P_{\ell})$ to denote exponentials of polynomials in future sections, and note that $E_{1+}(r)$ denotes the special case where the exponent is a linear function of $r$, allowing us to use Eq. \eqref{eq:simple_deriv}.

\subsection{Numerical testing}\label{sec:num_test_utility}
For testing purposes, note that numerical error quickly becomes an issue for higher order derivatives. Therefore, the proposed implementation was tested iteratively by first testing the expression for $t^{(1)}(r)$ versus numerical derivatives, then testing $t^{(2)}(r)$ versus the numerical derivative of the verified analytical expression for $t^{(1)}(r)$, etc. It should also be noted that because we are testing a generic expression for $t^{(n)}(r)$, we assume that testing for some $n$ that are not unreasonably large can serve as verification that the expressions hold generally, also for large $n$.

The result of tests up to $t^{(10)}$ are shown in Figs. \ref{fig:derivative_tests}-\ref{fig:last_derivative_test} using the test functions given in Table \ref{tab:numerical_tests_utility}.

Numerical tests were conducted to cover the cases where either $f$, $g$, or both, contained either only positive, only negative or a combination of positive and negative exponents. Tests were also conducted using both positive, negative, and zero-coefficients in the polynomials.

The test results indicate that the derived expressions and their implementation is correct, as the deviation between the analytical and numerical derivatives exhibit errors typically associated with numerical error, both in magnitude and behaviour.

\subsection{Efficiency considerations}
One thing to keep in mind is that the best-case time complexity of partitioning an integer is something like $\mathcal{O})(\exp{\sqrt{N}})$. The presented algorithms require that the number $n$ is partitioned when computing an $n$'th derivative. We can make some improvement on this issue in cases where $g$ is a polynomial of positive powers by skipping partitions containing larger numbers than the highest power in $g$, but if we have negative powers in $g$ we cannot get around the problem.

What we can do is reduce the number of $t$-functions our expressions contain, because higher-order derivatives become exponentially more time consuming to compute. This is explicitly exemplified in the case of the Patowski potential, where a sum of three polynomials with highest power $-10$, $-8$, and $-6$ respectively are combined to a single polynomial. 

\section{Specific potential models}

Having done the leg-work of deriving general expressions for the derivatives of our utility function $t(r)$, and testing those expressions, we now turn to some specific potential models used to represent ab initio potentials.

In the following, we will refer to functions of the type $f(r) \exp(g(r))$ where $f$ and $g$ are polynomials as $t$-functions.

\subsection{The Patowski potential}

The Patowski potential is an isotropic potential used to represent hydrogen. The potential reads
\begin{equation}
    \begin{split}
        \phi(r) &= \phi_r(r) + \phi_a(r), \\
        \phi_r(r) &= (a_0 + a_1 r + a_2 r^2 + a_3 r^3) \exp(b_0 + b_1 r) = t_r(r), \\
        \phi_a(r) &= \sum_{n = 3}^5 \frac{C_{2n}}{r^{2n}} \left(1 - \exp(-\delta r) \sum_{k = 0}^{2n} \frac{(\delta r)^k}{k!}\right).
    \end{split}
\end{equation}
The repulsive part, $\phi_r$, is already a $t$-function, so it's derivative is directly available.

The derivative of the attractive part is found by rewriting to
\begin{equation}
    \begin{split}
        \phi_a(r) &= \sum_{n = 3}^5 \frac{C_{2n}}{r^{2n}} - \sum_{n = 3}^{5} \exp(-\delta r) \sum_{k = -2n}^{0} \frac{C_{2n} \delta^{k + 2n} r^{k}}{(k + 2n)!}, \\
    \end{split}
\end{equation}
we can reduce the second part to a single polynomial by inverting the order of summation
\begin{equation}
    \begin{split}
        \phi_a(r) &= f_{a, 1} - \exp(-\delta r) \sum_{n = 3}^{5} \sum_{k = -2n}^{0} \frac{C_{2n} \delta^{k + 2n} r^{k}}{(k + 2n)!} \\
        &= f_{a, 1} - \exp(-\delta r) \sum_{k = -10}^{0} r^{k} \sum_{n = n_k}^5 \frac{C_{2n} \delta^{k + 2n} }{(k + 2n)!}
    \end{split}
\end{equation}
where $n_k = 3 + \big\lfloor \frac{|\min\{5 + k, 0\}|}{2} \big\rfloor$
Such that the potential is expressed using the  coefficients given in Tab. \ref{tab:patowski_coeff}.

It may be useful to note that the form of $\phi_a$ in the Patowski potential is that commonly known as the ''Tang-Toennies'' form, which is used in many ab inito potentials.

\begin{table}[htb]
    \centering
    \caption{Coefficients of the Patowski potential expressed in terms of $t$-functions.}
    \begin{tabular}{c c c c c}
    \toprule
         & $k_{min}$ & $k_{max}$ & $k_{step}$ & $C$ \\
    \midrule
        $f_r$ & 1 & 3 & 1 & $a_k$ \\
        $g_r$ & 0 & 1 & 1 & $b_k$     \\
    \midrule
        $f_{a, 1}$ & -10 & -6 & 2 & $C_{-2k}$ \\
        $f_{a, n}$ & -6 & 0 & 1 & $\frac{C_{2n} \delta^{k + 2n}}{(k + 2n)!}$ \\
        $g_{a, n}$ & 1 & 1 & 1 & $- \delta$ \\
    \bottomrule
    \end{tabular}
    \label{tab:patowski_coeff}
\end{table}

\subsection{The HFD-B2 potential}
The HFD-B2 potential is part of a family of potentials called ''HFD-BN'' potentials. I haven't looked enough at them to say anything about what is common to different potentials in this family. We use an HFD-B2 potential to represent helium. The potential reads
\begin{equation}
    \begin{split}
        \phi(x) &= \phi_r(x) + \phi_a(x) \\
        \phi_r(x) &= a_0 \exp(b_1 x + b_2 x^2) = t_r(x) \\
        \phi_a(x) &= - F(x) \sum_{k = 3}^{5} \frac{C_{2k}}{x^{2k}} \\
        F(x) &= 
        \begin{cases}
            \exp\left[\left(\frac{D}{x} - 1\right)^2 \right], & x < D \\
            1, & x \geq D
        \end{cases}
    \end{split}
\end{equation}
with $x = \frac{r}{r_m}$, with $r_m$ denoting the position of the potential minimum.

Again, the repulsive part is already in the form of a $t$-function, and poses no issue as-is.

We can rewrite the attractive part as 
\begin{equation}
    \phi_a(x) = 
    \begin{cases}
        f_a(x) \exp\left[\frac{D^2}{x^2} - \frac{2D}{x} + 1\right]& x < D\\
        f_{a}(x), & x \geq D
    \end{cases},
\end{equation}
in which both parts are on $t$-function form. The coefficients for the HFD-B2 potential are given in Tab. \ref{tab:hfdb2_coeff}

\begin{table}[htb]
    \centering
    \caption{Coefficients of the HFD-B2 potential expressed in terms of $t$-functions.}
    \begin{tabular}{c c c c c}
    \toprule
         & $k_{min}$ & $k_{max}$ & $k_{step}$ & $C$ \\
    \midrule
        $f_r$ & 0 & 0 & 1 & $a_0$ \\
        $g_r$ & 1 & 2 & 1 & $b_k$     \\
    \midrule
        $f_{a}$ & 6 & 10 & 2 & $C_{2k}$ \\
        $g_{a}$ & -2 & 0 & 1 & $\{D^2, -2D, 1\}$\\
    \bottomrule
    \end{tabular}
    \label{tab:hfdb2_coeff}
\end{table}

\subsection{The Modified Tang-Toennies potential}
The ''Tang-Toennies'' potential seems to turn up everywhere, but I've never seen (or looked for) the original expression - people seem to use a plethora of modifications of the original potential. The potential given here is used for Argon, it reads
\begin{equation}
    \begin{split}
        \phi(r) &= \phi_r(r) + \phi_a(r) \\
        \phi_r(r) &= a_0 \exp\left(a_{-2}r^{-2} + a_{-1}r^{-1} + a_1 r + a_2 r^2\right) \\
        \phi_a(r) &= \sum_{n=3}^{8} \frac{C_{2n}}{r^{2n}}\left(1 - \exp(-\delta r) \sum_{k = 0}^{2n} \frac{(\delta r)^k}{k!}\right)
    \end{split}
\end{equation}
and we immediately recognize this as essentially exactly the same form as the Patowski potential, only with a slightly different repulsive term, and three additional terms in the attractive part. Thus, we refer to Tab. \ref{tab:patowski_coeff} for the appropriate translation of coefficients.

\clearpage
\appendix
\section{Numerical testing of analytical derivatives of utility functions}

The analytical expressions for $n$'th order derivatives of the utility function $t(x) = f(x) \exp(g(x))$, with $f$ and $g$ polynomials were tested numerically as described in Sec. \ref{sec:num_test_utility}. The test functions are given in Tab. \ref{tab:numerical_tests_utility}, and the test results are given in Figs. \ref{fig:derivative_tests}-\ref{fig:last_derivative_test}.

\begin{table}[h!]
    \centering
    \caption{Coefficients and exponents of the functions $t_i = f_i(x) \exp(g_i(x))$.}
    \begin{tabular}{c c c c c c c c}
    \toprule
        & $k_{min}$ & $k_{max}$ & \multicolumn{5}{c}{C} \\
    \midrule
         $f_1$ & 0 & 4 & 1 & 2 & 3 & -2 & 4 \\
         $g_1$ & 0 & 3 & 1 & -1 & 1 & -0.5 & \\
    \midrule
         $f_2$ & -2 & 2 & -1.0 & 10.0 & 3.0 & 4.0 & -2.0\\
         $g_2$ & 0 & 3 & 1.0 & -1.0 & 1.0 & -0.5\\
    \midrule
         $f_3$ & -10 & -6 & -5.0 & 2.0 & -3.0 & 4.0 & -1.0\\
         $g_3$ & 0 & 3 & 2.0 & 1.0 & -3.0 & 1.0\\
    \midrule 
        $f_4$ & 0 & 4 & 5.0 & -1.0 & 0.0 & -3.0 & 4.0\\
        $g_4$ & -2 & 2 & -2.0 & 3.0 & 5.0 & 0.0 & -1.0\\
	\midrule 
		$f_5$ & -2 & 2 & 5.0 & -1.0 & 0.0 & -3.0 & 4.0\\
		$g_5$ & -2 & 2 & -2.0 & 3.0 & 5.0 & 0.0 & -1.0\\
	\midrule 
		$f_6$ & -8 & -4 & 5.0 & -1.0 & 0.0 & -3.0 & 4.0\\
		$g_6$ & -2 & 2 & -2.0 & 3.0 & 5.0 & 0.0 & -1.0\\
    \midrule 
		$f_7$ & 0 & 4 & -5.0 & -1.0 & 0.0 & -3.0 & 4.0\\
		$g_7$ & -10 & -6 & -2.0 & 3.0 & 5.0 & 0.0 & -1.0\\
    \midrule 
		$f_8$ & -1 & 3 & 5.0 & -1.0 & 0.0 & -3.0 & 4.0\\
		$g_8$ & -5 & -1 & 2.0 & -3.0 & 5.0 & 1.0 & -1.0\\
    \midrule 
		$f_9$ & -8 & -4 & 0.0 & -1.0 & 0.0 & -3.0 & 4.0\\
		$g_9$ & -19 & -15 & 2.0 & -3.0 & 5.0 & 1.0 & -1.0\\
    \bottomrule
    \end{tabular}
    \label{tab:numerical_tests_utility}
\end{table}

\begin{figure}[p]
    \centering
    \includegraphics[width=\linewidth]{analytical_nthderivative.pdf}
    \caption{Numerical test of the analytical expressions for the $n$'th derivative of $t_1(x)$.}
    \label{fig:derivative_tests}
\end{figure}

\begin{figure}[p]
    \centering
    \includegraphics[width=\linewidth]{analytical_nthderivative_2.pdf}
    \caption{Numerical test of the analytical expressions for the $n$'th derivative of $t_2(x)$.}
\end{figure}

\begin{figure}[p]
    \centering
    \includegraphics[width=\linewidth]{analytical_nthderivative_3.pdf}
    \caption{Numerical test of the analytical expressions for the $n$'th derivative of $t_3(x)$.}
\end{figure}

\begin{figure}[p]
    \centering
    \includegraphics[width=\linewidth]{analytical_nthderivative_4.pdf}
    \caption{Numerical test of the analytical expressions for the $n$'th derivative of $t_4(x)$.}
\end{figure}

\begin{figure}[p]
    \centering
    \includegraphics[width=\linewidth]{analytical_nthderivative_5.pdf}
    \caption{Numerical test of the analytical expressions for the $n$'th derivative of $t_5(x)$.}
\end{figure}

\begin{figure}[p]
    \centering
    \includegraphics[width=\linewidth]{analytical_nthderivative_6.pdf}
    \caption{Numerical test of the analytical expressions for the $n$'th derivative of $t_6(x)$.}
\end{figure}

\begin{figure}[p]
    \centering
    \includegraphics[width=\linewidth]{analytical_nthderivative_7.pdf}
    \caption{Numerical test of the analytical expressions for the $n$'th derivative of $t_7(x)$.}
\end{figure}

\begin{figure}[p]
    \centering
    \includegraphics[width=\linewidth]{analytical_nthderivative_8.pdf}
    \caption{Numerical test of the analytical expressions for the $n$'th derivative of $t_8(x)$.}
\end{figure}

\begin{figure}[p]
    \centering
    \includegraphics[width=\linewidth]{analytical_nthderivative_9.pdf}
    \caption{Numerical test of the analytical expressions for the $n$'th derivative of $t_9(x)$.}
    \label{fig:last_derivative_test}
\end{figure}

\end{document}
